{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver Segmentation with ConvDeconv architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook, we'll load a pretrained ConvDeconv model and predict on test images.\n",
    "#### Training code at the end of the notebook lets you train your own ConvDeconv model\n",
    "\n",
    "First, the needed imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import SimpleITK as sitk\n",
    "import scipy.misc as misc\n",
    "import scipy.ndimage as snd\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions:\n",
    "\n",
    "#### display_image_label_and_output:\n",
    "    A matplotlib function to plot the image, its label and the corresponding output from the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_image_label_and_output(image, label, output):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    plt.imshow(label, alpha = 0.5)\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(output, cmap = 'gray')\n",
    "    plt.imshow(label, alpha = 0.5)\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict_on_test_data:\n",
    "    given the model and the number of files, we predict on those and display the outputs using the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_on_test_data(model, n_files = 20):\n",
    "    test_files = os.listdir('test_images')\n",
    "    test_imgs = [os.path.join('test_images',f) for f in test_files if 'img' in f][:n_files]\n",
    "    test_labels = [f.replace('img', 'label') for f in test_imgs][:n_files]\n",
    "    for f,g in zip(test_imgs, test_labels):\n",
    "        img_arr = imageio.imread(f)\n",
    "        img_arr = (np.float32(img_arr) - img_arr.min())/(img_arr.max() - img_arr.min())\n",
    "        label_arr = imageio.imread(g)\n",
    "        label_arr = np.uint8((label_arr - label_arr.min())/(label_arr.max() - label_arr.min()))\n",
    "        # input to neural net has to be of form NCWH\n",
    "        inputs = img_arr[None,None,:,:]\n",
    "        inputs = Variable(torch.from_numpy(inputs), volatile = True)\n",
    "        outs = model.forward(inputs)\n",
    "        _, outs = torch.max(outs, 1)\n",
    "        output_arr = outs.data.numpy()[0]\n",
    "        display_image_label_and_output(img_arr, label_arr, output_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvDeconv Network architecture\n",
    "\n",
    "### nn.Sequential\n",
    "    A sequential container. Modules will be added to it in the order they are passed in the constructor\n",
    "\n",
    "### nn.Conv2d\n",
    "\n",
    "    Applies a 2D convolution over an input signal composed of several input planes.\n",
    "    stride controls the stride for the cross-correlation, a single number or a tuple.\n",
    "    padding controls the amount of implicit zero-paddings on both sides for padding number of points for each dimension.\n",
    "    dilation controls the spacing between the kernel points; also known as the Ã  trous algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvDeconv(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(ConvDeconv, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, kernel_size=3, padding=1), nn.BatchNorm2d(32))\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128))\n",
    "        self.conv4 = nn.Sequential(nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128))\n",
    "        \n",
    "        self.upconv1 = nn.Sequential(nn.ConvTranspose2d(128,128,stride=2, kernel_size=2), nn.BatchNorm2d(128))\n",
    "        self.conv5 = nn.Sequential(nn.Conv2d(128,64, kernel_size=3, padding=1), nn.BatchNorm2d(64))\n",
    "        \n",
    "        self.upconv2 = nn.Sequential(nn.ConvTranspose2d(64,32,stride=2, kernel_size=2), nn.BatchNorm2d(32))\n",
    "        self.conv6 = nn.Sequential(nn.Conv2d(32,2, kernel_size=3, padding=1), nn.BatchNorm2d(2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv2(F.relu(self.conv1(x))), inplace=True)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.conv4(F.relu(self.conv3(x))), inplace=True)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.conv5(F.relu(self.upconv1(x))))\n",
    "        x = self.conv6(F.relu(self.upconv2(x)))\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvDeconv()\n",
    "print(model)\n",
    "predict_on_test_data(model, n_files = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network loaded with trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('pretrained_models/conv-deconv_cpu.tar')['state_dict']\n",
    "model = ConvDeconv()\n",
    "model.load_state_dict(state)\n",
    "predict_on_test_data(model, n_files = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Code (Take Home)\n",
    "Additional requirements : GPU | Additional dependencies : progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SimpleTrainer(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.optimizer = optimzer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def forward_backward(inputs, labels):\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "        inputs = Variable(inputs).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        self.optimizer.zero_grad()\n",
    "        outputs = self.model.forward(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.data[0]\n",
    "\n",
    "    def forward(inputs, labels):\n",
    "        inputs = torch.from_numpy(inputs).float()\n",
    "        labels = torch.from_numpy(labels).long()\n",
    "        inputs = Variable(inputs, volatile=True).cuda()\n",
    "        labels = Variable(labels, volatile=True).cuda()\n",
    "        outputs = self.model.forward(inputs)\n",
    "        loss = self.loss_fn(outputs, labels)\n",
    "        return loss.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n",
    "\n",
    "The 2D slices are saved in .h5 format (H5 file is a data file saved in the Hierarchical Data Format (HDF). It contains multidimensional arrays of scientific data.)\n",
    "Images and labels are stored as two datasets in the h5 file and can be accessed by file_obj\\['image'\\] and file_obj\\['label'\\]\n",
    "\n",
    "We get the images and labels from it, randomise it and split it for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    # Reading the .h5\n",
    "    x = h5py.File('2DLiverSlices_128.h5','r')\n",
    "    \n",
    "    # Getting the images and the labels\n",
    "    images = x['image'][:]\n",
    "    labels = x['label'][:]\n",
    "    x.close()\n",
    "    \n",
    "    randperm = np.random.permutation(images.shape[0])\n",
    "    images = images[randperm]\n",
    "    labels = labels[randperm]\n",
    "    \n",
    "    # Splitting the data into training and validation\n",
    "    train_images = images[:1500]\n",
    "    train_labels = labels[:1500]\n",
    "    val_images = images[1500:]\n",
    "    val_labels = labels[1500:]    \n",
    "    return train_images, train_labels, val_images, val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the hyper-parameter for the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100  # Number of iterations for training the newtork\n",
    "BATCH_SIZE = 48  # Number of training example to be fed to the network\n",
    "PATCH_SIZE = [128,128]  # the input size of the image (L*B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "\n",
    "## Optimization:\n",
    "Use the optim package to define an Optimizer that will update the weights of the model for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ConvDeconv().cuda()\n",
    "# lr is the learning rate for optimization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay=5e-5)\n",
    "trainer = SimpleTrainer(model,nn.NLLLoss2d(), optimizer)\n",
    "train_images, train_labels, val_images, val_labels = get_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    print('Epoch: ' + str(i))\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for j in bar(range(0, train_images.shape[0], BATCH_SIZE)):\n",
    "        image_batch, label_batch = train_images[j: j+BATCH_SIZE], train_labels[j: j+BATCH_SIZE]\n",
    "        image_batch = image_batch.reshape(image_batch.shape[0], 1, PATCH_SIZE[0], PATCH_SIZE[1])\n",
    "        train_loss.append(trainer.forward_backward(image_batch, label_batch))\n",
    "    print('Train loss: ' + str(np.array(train_loss).mean()))\n",
    "    \n",
    "    torch.save({'state_dict':model.cpu().float().state_dict()}, 'conv-deconv_cpu.tar')\n",
    "    model.cuda()\n",
    "    # validate\n",
    "    \n",
    "    model.eval()    \n",
    "    val_loss = []\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for j in bar(range(0, val_images.shape[0], BATCH_SIZE)):\n",
    "        image_batch, label_batch = val_images[j: j+BATCH_SIZE], val_labels[j: j+BATCH_SIZE]\n",
    "        image_batch = image_batch.reshape(image_batch.shape[0], 1, PATCH_SIZE[0], PATCH_SIZE[1])\n",
    "        val_loss.append(trainer.forward(image_batch, label_batch))\n",
    "    print('Val loss: ' + str(np.array(val_loss).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show results on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "inputs = Variable(torch.from_numpy(val_images[3].reshape(1,1,128,128))).cuda()\n",
    "out = model.forward(inputs)\n",
    "out = np.argmax(out.data.cpu().numpy(), axis=1).reshape(128,128)\n",
    "plt.figure()\n",
    "plt.imshow(val_images[3], cmap = 'gray')\n",
    "plt.figure()\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
